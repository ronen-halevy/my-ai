# Gradient Descent Optimization Algorithms
 Momentum, Adagrad, and Adam actually
 
 SGD
RMSprop
Adam
Adadelta
Adagrad
Adamax
Nadam
Ftrl
