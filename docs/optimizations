---
layout: default
title: Optimization Algorithms
nav_order: 2
---

# Optimization Algorithms - Gradient Descent Variations Algorithms

The  fitting algorithm executed during the Training phase is most commonly carried by the Gradient Descent optimization algorithm and its variations, presented in previous posts. This post reviews the Gradient Descent and its variations listed below:

**Stochastic Gradient Descent**
**Momentum**
**Adagrad**
**RMSprop**
**Adam**
**tensorflow**
**SGD algorithm**
**SGD with Momentum algorithm**
**Adagrad algorithm**
**Adadelta algorithm**
**Adam algorithm**
**Adamax algorithm**
**FTRL algorithm**
**NAdam algorithm**
**RMSprop algorithm**


## Stochastic Gradient Descent
This Gradient Descent variant, which runs and update iteration per a single training example is caleed **Stochastic Gradient Descent** abrivated to **SGD**
Why Stochastic? Because the gradient is calculated per a single sample and not for the entire m examples of the data set. As a result of that, the gradient convergence iterative process is expected to be noisy. Still, SGD proves to fastly converge. However that, current High Processing Computing (HPC) devices, e.g. GPUs, are tailored for vectorized computations. Otherwise they are not vey efficient. As an alternative to SGD, Batch algoritm, AKA Deterministic Methods (as oposed to Stochastic) are more efficient with vectorized computation machines. 




Here's the basic formula of Gradient Descent:

### Eq. 1 Gradient Descent

\\(w=w-\alpha \cdot \frac{\partial L(w)}{\partial w}\\)

Where \\(L(w)\\) is a Loss function, which expresses the prediction's accuracy calculated for a every Training data example.

Eq. 1 expresses a single iteration of the optimization algorithm, at which the Gradient Descent update is calculated per each Training data example. This Gradient Descent variant, which runs and update iteration per a single training example is caleed **Stochastic Gradient Descent** abrivated to **SGD**. Why Stochastic? Because the gradient is calculated per a single sample and not for the entire m examples of the data set. As a result of that, the gradient convergence iterative process is expected to be noisy. Still, SGD proves to fastly converge. However that, current High Processing Computing (HPC) devices, e.g. GPUs, are tailored for vectorized computations. Otherwise they are not vey efficient. As an alternative to SGD, Batch algoritm, AKA Deterministic Methods (as oposed to Stochastic) are more efficient with vectorized computation machines. 




The objective of DNNs (Data Neural Networks) training, is to find the set of coefficents which minimizes a cost function. The cost expresses the error between the expected values and the actually predicted values. 
Gradient Descent, and its various variations, are the most commonly used algorithms to find that cost minimizing coefficents set. This post reviews the Gradient Descent and its variations listed below.

## Stochastic Gradient Descent




## Momentum
## Adagrad
## RMSprop
## Adam
tensorflow
SGD algorithm
SGD with Momentum algorithm
Adagrad algorithm.
Adadelta algorithm.
Adam algorithm.
Adamax algorithm.
FTRL algorithm.
NAdam algorithm.
RMSprop algorithm.









used for finding that set of minimizing coefficents. tech for finding the set of minimizing parameters is Gradient Descent, and function parameters are fitted during training, by minimizing a cost function which determines the error between the expected and predicted values. To most commonly used algorithm for finding the  minimum, is Gradient Descent, and its various variations. This post reviews the various optimization algorithms.







fare traine, is by minimizing a cost functionGradieThe most common method to train a neural network is by using gradient descent (SGD). The way this works is you define a loss function 
that expresses how well your weights & biases allow the network to fit your training data. A higher loss means that the network is bad and makes a lot of errors while a low loss generally means that the network performs well. You can then train your network by adjusting the network parameters in a way that reduces the loss.



coursera:
Mini Batch


Training with batch of all m examples - 1 update (step of gradient descent) after each cycle
Mini Batch - 1000 examples...runs faster for big training set


